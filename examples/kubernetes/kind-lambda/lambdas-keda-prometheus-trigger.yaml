# 
# Deploy with:
# kubectl apply -f lambdas-keda-prometheus-trigger.yaml
#
# Remove with:
# kubectl delete -f lambdas-keda-prometheus-trigger.yaml
#

# Deploy echo-lambda
kind: Deployment
apiVersion: apps/v1
metadata:
  name: echo-lambda
  namespace: lambda
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: echo-lambda
  template:
    metadata:
      labels:
        app.kubernetes.io/name: echo-lambda
    spec:
      securityContext:
        # Arbitrary uid. For systems that automatically run as a non-root
        # user like Openshift this likely isn't needed.
        runAsUser: 1000
      # When configured as an initContainer (with KUBERNETES_INIT_CONTAINER set)
      # the Runtime API Daemon copies itself, e.g the lambda-runtime-api-daemon
      # executable, to /tmp and then exits. This allows the executable to be
      # written to a volume and subsequently "injected" into the Lambda
      # Container. We write it to /usr/local/bin/aws-lambda-rie because AWS
      # images bundle the Runtime Image Emulator and the Runtime API Daemon
      # replaces that, allowing unmodified AWS base images to be used.
      initContainers:
        - name: lambda-runtime-api-daemon
          image: localhost:5000/lambda-runtime-api-daemon
          securityContext:
            # Run with all privileges removed and with a read only root filesystem
            privileged: false
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities:
              drop: ["ALL"]
          env:
          - name: KUBERNETES_INIT_CONTAINER # Just needs to be set
          volumeMounts:
          - name: lambda-runtime-api-daemon
            mountPath: /tmp
      containers:
        - name: echo-lambda
          image: localhost:5000/echo-lambda
          securityContext:
            # Run with all privileges removed and with a read only root filesystem
            privileged: false
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities:
              drop: ["ALL"]
          env:
          - name: AWS_LAMBDA_FUNCTION_NAME
            #value: echo-lambda
            # For variety set the value of this from the labels.
            # https://kubernetes.io/docs/concepts/workloads/pods/downward-api/
            # It might be nice to do this from the Deployment name, but I don't
            # believe that this is supported so using the label is a compromise.
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['app.kubernetes.io/name']
          - name: AWS_LAMBDA_FUNCTION_TIMEOUT
            value: "60"
          - name: AMQP_URI
            value: amqp://rabbitmq.messaging:5672
          volumeMounts:
            # Mount lambda-runtime-api-daemon as /usr/local/bin/aws-lambda-rie
            # so we may use unmodified AWS base images if we wish.
          - name: lambda-runtime-api-daemon
            mountPath: /usr/local/bin/aws-lambda-rie
            subPath: lambda-runtime-api-daemon
            # Give the Lambda a writeable /tmp
          - name: tmp
            mountPath: /tmp
      volumes:
      - name: lambda-runtime-api-daemon
        emptyDir: {}
      - name: tmp
        emptyDir: {}

---
# Deploy image-greyscale-lambda
kind: Deployment
apiVersion: apps/v1
metadata:
  name: image-greyscale-lambda
  namespace: lambda
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: image-greyscale-lambda
  template:
    metadata:
      labels:
        app.kubernetes.io/name: image-greyscale-lambda
    spec:
      securityContext:
        # Arbitrary uid. For systems that automatically run as a non-root
        # user like Openshift this likely isn't needed.
        runAsUser: 1000
      # When configured as an initContainer (with KUBERNETES_INIT_CONTAINER set)
      # the Runtime API Daemon copies itself, e.g the lambda-runtime-api-daemon
      # executable, to /tmp and then exits. This allows the executable to be
      # written to a volume and subsequently "injected" into the Lambda
      # Container. We write it to /usr/local/bin/aws-lambda-rie because AWS
      # images bundle the Runtime Image Emulator and the Runtime API Daemon
      # replaces that, allowing unmodified AWS base images to be used.
      initContainers:
        - name: lambda-runtime-api-daemon
          image: localhost:5000/lambda-runtime-api-daemon
          securityContext:
            # Run with all privileges removed and with a read only root filesystem
            privileged: false
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities:
              drop: ["ALL"]
          env:
          - name: KUBERNETES_INIT_CONTAINER # Just needs to be set
          volumeMounts:
          - name: lambda-runtime-api-daemon
            mountPath: /tmp
      containers:
        - name: image-greyscale-lambda
          image: localhost:5000/image-greyscale-lambda
          securityContext:
            # Run with all privileges removed and with a read only root filesystem
            privileged: false
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities:
              drop: ["ALL"]
          env:
          - name: AWS_LAMBDA_FUNCTION_NAME
            #value: image-greyscale-lambda
            # For variety set the value of this from the labels.
            # https://kubernetes.io/docs/concepts/workloads/pods/downward-api/
            # It might be nice to do this from the Deployment name, but I don't
            # believe that this is supported so using the label is a compromise.
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['app.kubernetes.io/name']
          - name: AWS_LAMBDA_FUNCTION_TIMEOUT
            value: "60"
          - name: AMQP_URI
            value: amqp://rabbitmq.messaging:5672
          volumeMounts:
            # Mount lambda-runtime-api-daemon as /usr/local/bin/aws-lambda-rie
            # so we may use unmodified AWS base images if we wish.
          - name: lambda-runtime-api-daemon
            mountPath: /usr/local/bin/aws-lambda-rie
            subPath: lambda-runtime-api-daemon
            # Give the Lambda a writeable /tmp
          - name: tmp
            mountPath: /tmp
      volumes:
      - name: lambda-runtime-api-daemon
        emptyDir: {}
      - name: tmp
        emptyDir: {}

---
# Deploy KEDA ScaledObject to scale echo-lambda Deployment based on queue depth,
# but in this case rather than use the native RabbitMQ scaler instead use KEDA's
# Prometheus trigger with the query rabbitmq_queue_messages{queue="echo-lambda"}
# https://keda.sh/docs/2.14/concepts/scaling-deployments/
# https://keda.sh/docs/2.14/scalers/rabbitmq-queue/
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: echo-lambda
  namespace: lambda
spec:
  scaleTargetRef:
    kind: Deployment
    apiVersion: apps/v1
    name: echo-lambda
  pollingInterval:  2
  cooldownPeriod:   10
  #idleReplicaCount: 0
  # Note we set minReplicaCount to 1 because although Keda can scale to zero
  # the default behaviour of lambda-runtime-api-daemon us to autodelete the
  # AMQP queue that maps to the function name. If the queue is deleted then
  # the metric Keda uses to scale back up won't be available.
  # The autodelete behaviour may be made configurable in due course, though
  # the presence of the queue is a useful proxy for the availability of the
  # Lambda and lambda-server uses the AMQP mandatory flag to ensure that a
  # function is available. If the queue is present but the function is not
  # actually deployed requests will still be enqueued. Even without k8s scale
  # to zero the lambda-runtime-api-daemon in the Lambda container actually
  # scales the Lambda runtime process to zero after a timeout so in practice
  # only the lambda-runtime-api-daemon will be active in the Lambda container.
  minReplicaCount:  1
  maxReplicaCount:  50
  triggers:
  - type: prometheus
    metadata:
      # Required fields:
      serverAddress: http://prometheus.monitoring.svc:9090
      # Note: query must return a vector/scalar single element response
      query: sum(rabbitmq_queue_messages{queue="echo-lambda"})
      #query: sum(rate(http_requests_total{deployment="my-deployment"}[2m]))
      threshold: "100" # message backlog target per instance
      #activationThreshold: "0" # Optional. Activation threshold
      # Optional fields:
      #namespace: example-namespace  # for namespaced queries, eg. Thanos
      #customHeaders: X-Client-Id=cid,X-Tenant-Id=tid,X-Organization-Id=oid # Optional. Custom headers to include in query. In case of auth header, use the custom authentication or relevant authModes.
      #ignoreNullValues: true # Default is `true`, which means ignoring the empty value list from Prometheus. Set to `false` the scaler will return error when Prometheus target is lost
      unsafeSsl: "true"

---
# Deploy KEDA ScaledObject to scale image-greyscale-lambda Deployment based on queue depth,
# but in this case rather than use the native RabbitMQ scaler instead use KEDA's
# Prometheus trigger with the query rabbitmq_queue_messages{queue="image-greyscale-lambda"}
# https://keda.sh/docs/2.14/concepts/scaling-deployments/
# https://keda.sh/docs/2.14/scalers/rabbitmq-queue/
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: image-greyscale-lambda
  namespace: lambda
spec:
  scaleTargetRef:
    kind: Deployment
    apiVersion: apps/v1
    name: image-greyscale-lambda
  pollingInterval:  2
  cooldownPeriod:   10
  #idleReplicaCount: 0
  minReplicaCount:  1
  maxReplicaCount:  50
  triggers:
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.monitoring.svc:9090
      query: sum(rabbitmq_queue_messages{queue="image-greyscale-lambda"})
      threshold: "100" # message backlog target per instance
      unsafeSsl: "true"

